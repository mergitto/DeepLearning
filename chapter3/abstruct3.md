# ニューラルネットワーク
ニューラルネットワークはパーセプトロンのデメリットを解決できる

### パーセプトロンの得意分野
- 複雑な処理を表現できる
- 非線形な表現が可能になる

### パーセプトロンの苦手分野
- 重みの設定は手作業

ニューラルネットワークは適切な重みを自動で学習できるという重要な性質を持つ
本章では概要について説明する
図の左側の列を「入力層」、図の中間の列を「中間層（隠れ層）」、図の右側の列を「出力層」という

![ニューラルネットワーク](neural.png "ニューラルネットワーク")

前章にて出てきたパーセプトロンを表す式をよりシンプルに書き換えると以下のようになる
```
y = h(b + w1x1 + w2x2)

h(x) = 0 (x <= 0)
h(x) = 1 (x > 0)
```
h(x)という関数を用いて表している

h(x)が0を超えたら出力は１、そうでなければ出力は０となる

h(x)…入力信号の総和を出力信号に変換する関数は**活性化関数**と呼ばれている

## 活性化関数
活性化関数は閾値を境にして出力が切り替わる関数である。
これは「ステップ関数」や「階段関数」と呼ばれる
つまりパーセプトロンは活性化関数にステップ関数を利用している。パーセプトロンに利用しているステップ関数を変更することでニューラルネットワークへの世界へ進むことが出来る

### シグモイド関数
シグモイド関数はニューラルネットワークでよく利用される活性化関数の内の1つである。
以下のような式で表される
```math
h(x) = \flac{1}{1 + exp(-x)}\\
\frac{1}{2} - \frac{1}{3} = \frac{1}{6} \\
```
```math
\frac{1}{2} - \frac{1}{3} = \frac{1}{6} \\
\frac{a+b}{2ab}
```
